---
title: "Probabilistic Soundness Guarantees in LLM Reasoning Chains"
layout: single
excerpt: "We certify the soundness of LLM reasoning chains with probabilistic guarantees, especially under error propagation."
header:
  overlay_color: "#000"
  overlay_filter: "0.5"
  overlay_image: assets/images/ares/ares_banner_bw.png
  teaser: assets/images/ares/ares_banner_bw.png
  actions:
    - label: "Paper"
      url: https://arxiv.org/abs/2507.12948
    - label: "Code"
      url: https://github.com/fallcat/ares
authors:
  - Weiqiu You
  - Anton Xue
  - Shreya Havaldar
  - Delip Rao
  - Helen Jin
  - Chris Callison-Burch
  - Eric Wong


---
title: 'Probabilistic Soundness Guarantees in LLM Reasoning Chains'
date: 2025-11-03
author: Weiqiu You, Anton Xue, Shreya Havaldar, Delip Rao, Helen Jin, Chris Callison-Burch, Eric Wong
redirect_to: https://debugml.github.io/ares/
---

> Large language models (LLM) often make reasoning errors.
> However, current LLM-based error detection methods often fail to detect propagated errors because earlier errors can corrupt downstream judgments.
> To address this, we introduce **Autoregressive Reasoning Entailment Stability (ARES)**, an algorithmic framework for measuring reasoning soundness with statistical guarantees.
> ARES can reliably detect errors in long reasoning chains, especially propagated errors that other methods fail to catch.

When LLM reasoning goes wrong, there are several different failure modes.
For example:

## (hidden)
{: .hidden .no_toc}


<div class="chain-compare">
  <!-- Context box spanning both columns -->
  <div class="context-card">
    <div class="chain-title">Context</div>
    <p>The denominator of a fraction is <span class="context-em">7 less than 3 times</span> the numerator.</p>
    <p>If the fraction is equivalent to <span class="context-em">2/5</span>, what is the numerator?</p>
  </div>

  <!-- Left card -->
  <div class="chain-card">
    <div class="chain-title">Correct Chain</div>
    <ol class="steps">
      <li><span class="text">Let the numerator be <em>x</em></span></li>
      <li><span class="text">The denominator is <em>3x − 7</em></span></li>
      <li><span class="text">So <em>x / (3x − 7) = 2/5</em></span></li>
      <li><span class="text">Therefore, <em>5x = 6x − 14</em></span></li>
      <li><span class="text">Finally, we get <strong>x = 14</strong> ✓</span></li>
    </ol>
  </div>

  <!-- Right card -->
  <div class="chain-card">
    <div class="chain-title">Incorrect Chain</div>
    <ol class="steps">
      <li><span class="text">Let the numerator be <em>x</em></span></li>
      <li><span class="text">The denominator is <em>3x − 7</em></span></li>
      <li>
        <span class="text">So <em>x / (3x − 7) = <span style="background-color:rgba(255, 144, 47, 0.4);">3/5</span></em></span><br>
        <span class="badge warn">Ungrounded</span>
      </li>
      <li>
        <span class="text">Therefore, <em><span style='background-color:#ff000066; font-weight:bold'>5x = 9x − 20</span></em></span><br>
        <span class="badge err">Invalid</span>
      </li>
      <li>
        <span class="text">Finally, we get <strong><span style='background-color:#88008866; font-weight:bold'>x = 5</span></strong></span><br>
        <span class="badge prop">Propagated</span>
      </li>
    </ol>
  </div>
</div>

As illustrated in the example above, one type of error is an [<span style='color:orange; font-weight:bold'>**ungrounded error**</span>](https://arxiv.org/abs/2502.12289) --- a step that is incorrect with respect to the given context.
For example, the model might incorrectly copy a 2/5 in the context to be 3/5.
Another common error is an [<span style='color:red; font-weight:bold'>**invalid derivation**</span>](https://arxiv.org/abs/2502.12289) --- for example, deriving $5x=9x-20$ from $x/(3x-7)=3/5$ --- which is a logical misstep or miscalculation.
A third type of error involves [<span style='color:#880088; font-weight:bold'>**error propagation**</span>](https://arxiv.org/abs/2407.14790): even if the logic is valid, an incorrect starting assumption can lead to a wrong conclusion. For instance, using the incorrect claim $5x=9x-20$ to derive $x=5$ is logically valid but the derived claim is incorrect due to the initial error.
All of these errors are _unsound_ claims that undermine the soundness of a reasoning chain.

Current error detection methods, such as LLM judges and Process Reward Models, typically aim to identify all errors at once.
However, an LLM attempting to detect all errors with a single call is often unreliable as it can be distracted by unsound information in other steps.

To address these limitations, we introduce **Autoregressive Reasoning Entailment Stability (ARES)**, an LLM-based framework for automated error detection.
Our main idea is to certify a reasoning chain _step-by-step_: the soundness of successive claims are inductively computed from the stability of prior claims.
Theoretically, we show that this approach admits strong yet sample-efficient statistical guarantees.
Empirically, we excel where prior methods fall short, particularly in catching propagated errors within very long reasoning chains.

<!-- ## Using an LLM to Check Soundness of Reasoning Chains

Let's consider different kinds of situations where an LLM can fail to reliably decide the soundness of reasoning chain.

Suppose we have a reasoning chain as in the previous example, and we just ask an LLM to tell us if each step is sound or unsound.
The LLM can be misled by step 4 when checking step 5: oh, because 5x = 9x − 20, we can then derive x = 5.
Just because a previous step logically lead to the next step does not mean the next step is sound --- it can be unsound if it relies on an unfounded premise.

Then we can be motivated to use more principled methods to check each step.
We can use an entailment model and ask it to check a step with not all the information, but only a subset of information. -->

## The Challenge of Using LLMs to Verify Reasoning

Using a large language model (LLM) to reliably determine the soundness of a reasoning chain presents several challenges.

A naive approach might be to ask an LLM to judge each step as either sound or unsound. However, this method is prone to failure. Consider the incorrect chain from our example: an LLM might be misled by step 4 ("Therefore, *5x = 9x − 20*") when evaluating step 5 ("Finally, we get **x = 5**"). The model could correctly see that step 5 *logically follows* from step 4, but fail to recognize that step 5 is ultimately unsound because it relies on an unsound premise.

This demonstrates that simple, holistic judgments with a single LLM call are insufficient. A more principled method is needed, perhaps one that uses an entailment model to check each step using only a specific subset of information, rather than the entire context.

### Detecting Reasoning Errors with an Entailment Model

An entailment model determines whether a hypothesis logically follows from a premise (entailment) or whether the opposite of the hypothesis follows from the premise (contradiction). When verifying a reasoning step, we have several options for selecting the premise: we can use all previous claims leading up to the current step, only the base claims from the original context, or check whether the current claim contradicts each previous claim individually.

However, each approach has fundamental limitations. Using all previous claims as the premise suffers from error propagation: if any earlier claim is unsound, we incorporate incorrect information into subsequent verification steps and can erroneously say the unsound steps are sound --- the same issue that arises when using an LLM to judge all steps holistically.

What if we restrict ourselves to only the base claims as premises? After all, these are sound claims provided in the context. This approach fails when the current step depends on a long chain of intermediate reasoning. Single-step entailment checking is insufficient; we need the sound information derived from prior inferences.

Other methods, such as [ROSCOE](https://arxiv.org/abs/2212.07919) and [ReCEval](https://arxiv.org/abs/2304.10703), check whether the current claim contradicts any previous claim through pairwise comparison. However, this approach also risks using unsound premises and can miss errors when multiple claims must be considered together to properly evaluate the current step.

In summary, current LLM- and entailment-model-based methods are unreliable for verifying claims in reasoning chains because they fail to use all necessary sound information while simultaneously excluding unsound information.

<!-- ### Detecting Reasoning Errors with an Entailment Model

An entailment model says a hypothesis is entailed by a premise if it logically follows the premise, and contradicted if the opposite of the hypothesis follows the premise.
There are some simple things we can try when checking a step: we can use all previous claims before the current reasoning step as the premise, or only the base claims present in the original context, or we can check if the current claim contradicts with any previous claim one by one.

However, all of these methods have inherent limitations.
Checking the soundness of a claim with all previous claims can fail from the same problem as using an LLM to judge all steps together:
If the previous claim is unsound, then we are using wrong information for checking later claims.

Then, what if we only use the base claims as premise? They are all sound claims given in the context.
This also won't work if there is a long reasoning chain before arriving at an intermediate conclusion.
A single-step entailment checking is not suffice; we need the sound information in the previous long reasonings.

Some other methods such as [ROSCOE](https://arxiv.org/abs/2212.07919) and [ReCEval](https://arxiv.org/abs/2304.10703) check if the current claim contradicts with any previous claim by comparing it with them one-by-one.
This can also suffer from using the wrong information as premise, and additionally insufficient information when we need multiple claims together to check the current claim.

Therefore, current LLM and entailment-model based methods are unreliable when checking if a claim in a reasoning chain is sound or unsound because they are not using all necessary and sound information. -->

<!-- ## Error Detection with ARES

To address these limitations, we pair step-by-step reasoning with step-by-step certification, and propose Autoregressive Reasoning Entailment Stability (ARES).

We first define a reasoning chain as a sequence of base claims $(C_1, \dots, C_n)$ that are given, and derived claims $(C_{n+1},\dots,C_{n+m})$ generated by an LLM.
A probabilistic entailment model $\mathcal{E}(P, H)\mapsto r$ estimates the probability that a premise $P$ entails a hypothesis $H$, where $r\in[0,1]$.

ARES gives a stability score $\tau_k$ for each derived claim $C_{n+k}$.
This score represents the expected entailment of $C_{n+k}$ by marginalizing over all $2^{n+k-1}$ possible subsets of valid preceding claims:

$$\tau_{k} = \sum_{\alpha \in \{0,1\}^{n+k-1}} \mathcal{E}(C (\alpha), C_{n+k}) \cdot \Pr[\alpha]$$

where the binary vector $\alpha \in \{0, 1\}^k$ indicates which claims to include ($\alpha_i = 1$) or exclude.

The probability of a premise combination, $\Pr[\alpha]$, is calculated autoregressively.
- For **base claims**, it is the product of their prior soundness probabilities $p_i$: 
$$\Pr[\alpha_{1:n}] = \prod_{i = 1}^{n} p_i ^{\alpha_i} (1 - p_i) ^{\alpha_i}$$
- For **derived claims**, the probability is updated inductively via the chain rule, conditioned on the entailment of the new claim:
$$\Pr[\alpha_{1:n+k}] = \Pr[\alpha_{1:n+k-1}] \,\cdot \quad\, \mathcal{E}(C (\alpha_{1:n+k-1}), C_{n+k})$$

{% include gallery id="gallery_algo" layout="" caption="**Autoregressive Reasoning Entailment Stability (ARES).** Each reasoning chain is decomposed into base and derived claims. ARES checks each derived claim step-by-step using only previously verified claims as premises. This figure shows the binary case; later we generalize it to probabilistic entailment." %} -->

## Error Detection with ARES

To address these limitations, we pair step-by-step reasoning with step-by-step certification, proposing Autoregressive Reasoning Entailment Stability (ARES).

We first define a reasoning chain as a sequence of base claims $(C_1, \dots, C_n)$ that are given in the context, followed by derived claims $(C_{n+1},\dots,C_{n+m})$ generated by an LLM. A probabilistic entailment model $\mathcal{E}(P, H) \mapsto r$ estimates the probability that a premise $P$ entails a hypothesis $H$, where $r\in[0,1]$.

ARES assigns a stability score $\tau_k$ to each derived claim $C_{n+k}$. This score represents the expected entailment of $C_{n+k}$ by marginalizing over all $2^{n+k-1}$ possible subsets of preceding claims:

$$\tau_{k} = \sum_{\alpha \in \{0,1\}^{n+k-1}} \mathcal{E}(C(\alpha), C_{n+k}) \cdot \Pr[\alpha]$$

where the binary vector $\alpha \in \{0, 1\}^{n+k-1}$ indicates which claims to include ($\alpha_i = 1$) or exclude ($\alpha_i = 0$) in the premise.

The probability of each premise combination, $\Pr[\alpha]$, is calculated autoregressively:
- For **base claims**, it is the product of their prior soundness probabilities $p_i$: 
$$\Pr[\alpha_{1:n}] = \prod_{i = 1}^{n} p_i^{\alpha_i} (1 - p_i)^{1-\alpha_i}$$
- For **derived claims**, the probability is updated inductively via the chain rule, conditioned on the entailment of each new claim:
$$\Pr[\alpha_{1:n+k}] = \Pr[\alpha_{1:n+k-1}] \cdot \mathcal{E}(C(\alpha_{1:n+k-1}), C_{n+k})^{\alpha_{n+k}}$$

{% include gallery id="gallery_algo" layout="" caption="**Autoregressive Reasoning Entailment Stability (ARES).** Each reasoning chain is decomposed into base and derived claims. ARES checks each derived claim step-by-step using only previously verified claims as premises. This figure shows the binary case; we later generalize to probabilistic entailment." %}

<!-- The key of ARES is that we check the soundness of a claim in a reasoning step based on probabilistic combinaions of previous claims' soundness. -->
<!-- The key of ARES is that we check the soundness of a claim in a reasoning step based on probabilistic sound combinaions of previous claims. -->
<!-- The key of ARES is that we check the soundness of a claim in a reasoning step with subsets of previous claims as premise weighted by their soundness. -->
<!-- TODO: this sentence sounds weird. -->
The key idea behind ARES is to evaluate each derived claim by considering all subsets of previous claims as potential premises, weighted by their probability of being sound.

### Certifying probabilistic soundness via efficient sampling

The above definition of soundness is convenient to define, but it is intractable to compute!
In the absence of additional problem structure, one must exhaustively enumerate over exponentially many configurations of premise inclusion-exclusions.

While _exact_ computation is difficult, our [previous work](https://debugml.github.io/soft-stability/) shows that we can efficiently certify stability in feature attributions to a high accuracy.
<!-- While _exact_ computation is difficult, our [previous work](https://debugml.github.io/soft-stability/) shows that _approximate_ estimation is both accurate and efficient. -->
The main idea is to sample a bunch of sub-reasoning chains, and then do a weighted average based on each sub-chain's likelihood.
This is illustrated in the following algorthm.

Suppose the reasoning chain consists of base claims $(C_1, \ldots, C_n)$ and derived claims $(C_{n+1}, \ldots, C_{n+m})$.
We can estimate ARES score $\tau_k$ for each derived claim in a reasoning chain inductively using an entailment model instantiated from an LLM.

<div class="notice--success">
  <!-- <strong>Algorithm. Autoregressive Reasoning Entailment Stability (ARES) Estimation</strong>
  Estimates the reasoning stability rate&nbsp;$\tau_k$ for each derived claim in a reasoning chain.<br><br> -->

  <strong>Algorithm. ARES Score Estimation.</strong>

  <div style="margin-left: 16px;">
    <strong>Step 1.</strong> <em>Sample base claims.</em><br>
    Draw $N$ i.i.d. random subsets, including each base claim $C_i, \ldots, C_n$ with probability $p_i$.<br><br>

    <strong>Step 2.</strong> <em>For each derived claim $C_{n+k}$ ($k=1\!:\!m$):</em><br>
    <div style="margin-left: 20px;">
      <strong>(a)</strong> For each sample $i$, compute $p_{n+k}^{(i)}$, the probability $C_{n+k}$ is entailed by prior included claims.<br>
      <strong>(b)</strong> Average entailment probabilities over $N$ samples to estimate $C_{n+k}$’s stability rate $\tau_k$.<br>
      <strong>(c)</strong> For each sample $i$, include $C_{n+k}$ for certifying future steps with probability $p_{n+k}^{(i)}$.<br>
      <strong>(d)</strong> Repeat until all derived claims are evaluated.<br>
    </div>
  </div>

<br>
  <div style="margin-left: 16px;">
    <strong>Guarantee.</strong>
    If the number of samples satisfies&nbsp;$N \ge \frac{\log(2/\delta)}{2\varepsilon^2}$,  
    then with probability at least&nbsp;$(1 - \delta)$, the estimated entailment stability rate&nbsp;$\hat{\tau}_k$ w.r.t. an entailment model $\mathcal{E}$
    for any claim&nbsp;$r$ satisfies&nbsp;$|\hat{\tau}_k - \tau_k| \le \varepsilon$.
  </div>
</div>
<!-- **Theorem 1.** (Ceritifying ARES via Sampling)
Let $N \geq \tfrac{\log(2m/\delta)}{2 \varepsilon^2}$ for any $\varepsilon > 0$ and $\delta > 0$.
Given an entailment model $\mathcal{E}$ and a reasoning chain with $m$ derived claims,
use $N$ i.i.d. samples to estimate each $\tau_k$.
Then, with probability at least $1 - \delta$, we have $|\hat{\tau}_k - \tau_k| \leq \varepsilon$ for all $k$.
{: .notice--info} -->


This algorithm is illustrated in the following example.
**Step 1:** We randomly sample inclusion of base claims based on prior probabilities for $N$ samples. 

{% include gallery 
id="gallery_sample_base_claims"
layout=""
caption=""
%}

**Step 2:** We then iteratively compute the estimated soundness for each step. 

**(a)** Every time, for each sample, we use the previously included claims as premise to compute the entailment rate of the next claim.

{% include gallery 
id="gallery_compute_entailment"
layout=""
caption=""
%}

**(b)** The ARES score for that claim is then the average of all those entailment rates for all the samples.

**(c)** In parallel, we sample from the entailment rate for the claim in each sample to decide whether or not to include it when certifying future claims for that sample.

{% include gallery 
id="gallery_sample_inclusion_derived_claims"
layout=""
caption=""
%}

Now that we have decided if we want to include this new derived claim in each sample, we can then use the inclusion/exclusion of the new claim to compute the estimated soundness rate of the next derived claim. 

{% include gallery 
id="gallery_iteration_1_complete"
layout=""
caption=""
%}


**(d)** We do this iteratively from the first derived claim to the last, until all claims in the reasoning chain are certified.

<!-- {% include gallery 
id="gallery_whole_algo"
layout=""
caption=""
%} -->


<!-- ## ARES Excels in Long Reasoning Chains with Propagated Errors

There are a couple of existing datasets for LLM reasoning error detection. -->
<!-- However, they often only contain labels of errors when they appear the first time -->
<!-- However, they often only contain labels of the first-occurring errors, and such errors usually only cover ungrounded statements and invalid derivations.
In order to check if ARES can really detect all kinds of errors (ungrounded, invalid, and propagated), we construct synthetic datasets such that we know they have long reasoning chains with propagated errors.

It is simple to construct such datasets:
Suppose we have a ground truth reasoning chain that iteratively apply rules from the context to make derivations.
If it applies a non-existing rule, then that step would be an error.
All the reasonings that follow will then all become unsound.

We create two synthetic datasets: ClaimTrees and CaptainCookRecipes, both based on ground truth chain/graph where we deliberately remove one rule of the graph from the context. -->
<!-- ClaimTrees contain synthetic rules, while CaptainCookRecipes is adapted from [CaptainCook4D](https://captaincook4d.github.io/captain-cook/)'s ground truth recipe graphs. -->

<!-- We can see from below examples that ARES excels at reliably detecting propagated errors in these synthetic datasets, while baseline performance deteriorates sharply with the issues we discussed earlier. -->

## ARES Excels in Long Reasoning Chains with Propagated Errors

Existing datasets for LLM reasoning error detection often only label the first error in a chain, typically covering ungrounded statements or invalid derivations. To evaluate whether ARES can detect *all* error types—including propagated ones—we construct synthetic datasets with long reasoning chains where a single early mistake causes all subsequent steps to become unsound.

Construction is simple: given a ground-truth chain that iteratively applies rules from context, we remove one rule. When the model incorrectly applies this missing rule, every following step becomes an error.

We build two synthetic datasets—ClaimTrees (synthetic rules) and CaptainCookRecipes (adapted from CaptainCook4D recipe graphs)—both containing such propagated-error structures.

Across these datasets, ARES reliably identifies downstream propagated errors, while baseline methods degrade significantly for the reasons discussed above.



### Example: ClaimTrees

<style>
/* -------- Claim table styling -------- */
.claims-wrap { margin-bottom: .4rem; }
.claims-caption { font-size: 0.75rem; color: #666; margin-top: .35rem; margin-bottom: 1rem}

.claims-table {
  --claim-w: 240px;   /* width of Claim column */
  --gt-w: 72px;       /* width of Ground Truth column */
  --table-bg: #f3f3f3;
}

.claims-table table {
  width: 100%;
  border-collapse: collapse;
  font-size: 0.6rem;
  background: var(--table-bg);
  table-layout: fixed;          /* respect <col> widths */
}

.claims-table th,
.claims-table td {
  padding: .35rem .55rem;
  border-bottom: 1px solid #e6e6e6;
  vertical-align: middle;
  background: var(--table-bg);  /* keeps sticky cells opaque */
  white-space: normal;          /* allow wrapping */
}

.claims-table thead th {
  background: #f7f2e7;
  font-weight: 700;
  white-space: normal;
  word-break: break-word;
  z-index: 4;
}

/* Context row */
.claims-table .context td {
  background: #faf9f7;
  font-style: italic;
  border-top: 2px solid #e6e6e6;
}

/* Numbers + chips */
.claims-table td.metric { text-align: center; font-variant-numeric: tabular-nums; white-space: nowrap; }

/* Base chip */
.claims-table .chip {
  display: inline-block;
  line-height: 1;
  padding: .12rem .38rem;
  border-radius: .5rem;
  margin-left: .25rem;
  border: 1px solid transparent;   /* normal thickness */
  font-size: .6em;
  font-weight: 700;
}

/* Thicker border when matching GT (and always on GT col) */
.claims-table .chip.thick { border-width: 3px; }

/* Colors */
.claims-table .ok  { background: #e8f5e9; border-color: #a5d6a7; }
.claims-table .bad { background: #ffebee; border-color: #ef9a9a; }

/* Column sizing via <colgroup> */
.claims-table .claim { width: var(--claim-w); min-width: var(--claim-w); }
.claims-table .gt    { width: var(--gt-w);  min-width: var(--gt-w); max-width: var(--gt-w); text-align: center; }
.claims-table .metriccol { width: calc((100% - var(--claim-w) - var(--gt-w)) / 8); }

/* Tighten GT padding so it doesn't look wide */
.claims-table th.gt, .claims-table td.gt { padding-left: .25rem; padding-right: .25rem; }

/* Sticky (frozen) first two columns */
.claims-table .sticky-claim { position: sticky; left: 0; z-index: 5; }
.claims-table .sticky-gt    { position: sticky; left: var(--claim-w); z-index: 4; }
.claims-table thead .sticky-claim,
.claims-table thead .sticky-gt { z-index: 6; }

/* Claim cells: clamp to two lines with ellipsis */
.claims-table .claim-text {
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-line-clamp: 2;
  overflow: hidden;
}

/* Optional: mobile adjustments */
@media (max-width: 860px) {
  .claims-table { --claim-w: 65vw; --gt-w: 60px; }
  .claims-table table { font-size: 0.6rem; }
}
</style>

<div class="claims-wrap">
  <div class="claims-table">
    <table>
      <colgroup>
        <col class="claim">
        <col class="gt">
        <col class="metriccol"><col class="metriccol"><col class="metriccol"><col class="metriccol">
        <col class="metriccol"><col class="metriccol"><col class="metriccol"><col class="metriccol">
      </colgroup>

      <thead>
        <tr>
          <th class="sticky-claim">Claim</th>
          <th class="sticky-gt gt"><em>Ground<br>Truth</em></th>
          <th>ARES (Ours)</th>
          <th>Entail-Prev</th>
          <th>Entail-Base</th>
          <th>ROSCOE-LI-Self</th>
          <th>ROSCOE-LI-Source</th>
          <th>ReCEval-Intra</th>
          <th>ReCEval-Inter</th>
          <th>LLM-Judge</th>
        </tr>
      </thead>

      <tbody>
        <!-- Context entirely in first column; wraps -->
        <tr class="context">
          <td class="sticky-claim">
            <strong>Context.</strong>
            <strong>Rules:</strong> H3 → AZ; SG → C6; C6 → GM; VD → H3; G8 → VD; D8 → U8; U8 → DG; DG → G8.
            <strong>Fact:</strong> I have D8. …
          </td>
          <td class="sticky-gt gt"></td>
          <td colspan="8"></td>
        </tr>

        <!-- Claim 5 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 5: I use rule (VD → H3) to derive H3</span></td>
          <!-- GT is always thick -->
          <td class="sticky-gt gt"><span class="chip ok thick">✓</span></td>
          <!-- Matches GT (✓) → thick -->
          <td class="metric"><strong>0.79</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
        </tr>

        <!-- Claim 6 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 6: I use rule (H3 → AZ) to derive AZ</span></td>
          <td class="sticky-gt gt"><span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>0.82</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
        </tr>

        <!-- Claim 7 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 7: I use rule (AZ → SG) to derive SG</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <!-- Matches GT (✗) → thick -->
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <!-- Differs from GT (✓ vs ✗) → normal (thin) -->
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
        </tr>

        <!-- Claim 8 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 8: I use rule (SG → C6) to derive C6</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="claims-caption">
    <strong>ClaimTrees example.</strong> After two correct steps (Claims 5–6), an initial error (Claim 7) using the non-existing rule AZ → SG causes a propagated error (Claim 8). Only <strong>ARES</strong> correctly judges all steps.
  </div>
</div>

<details>
<summary>Click for CaptainCookRecipes Example</summary>
<div markdown="1">

### Example: CaptainCookRecipes


<!-- ===== Example: CaptainCook4D ===== -->
<div class="claims-wrap">
  <div class="claims-table">
    <table>
      <colgroup>
        <col class="claim">
        <col class="gt">
        <col class="metriccol"><col class="metriccol"><col class="metriccol"><col class="metriccol">
        <col class="metriccol"><col class="metriccol"><col class="metriccol"><col class="metriccol">
      </colgroup>

      <thead>
        <tr>
          <th class="sticky-claim">Claim</th>
          <th class="sticky-gt gt"><em>Ground<br>Truth</em></th>
          <th>ARES (Ours)</th>
          <th>Entail-Prev</th>
          <th>Entail-Base</th>
          <th>ReCEval-Inter</th>
          <th>ReCEval-Intra</th>
          <th>ROSCOE-LI-Source</th>
          <th>ROSCOE-LI-Self</th>
          <th>LLM-Judge</th>
        </tr>
      </thead>

      <tbody>
        <!-- Context with all simplified sentX concatenated -->
        <tr class="context">
          <td class="sticky-claim">
            <strong>Context.</strong>
            Only after putting tomatoes on a serving plate, and if we have all the ingredients, we can then pour the egg mixture into the pan.
            Only after taking a tomato, and if we have all the ingredients, we can then cut the tomato into two pieces.
            Only after stopping stirring when it’s nearly cooked to let it set into an omelette, and if we have all the ingredients, we can then transfer the omelette to a plate and serve with the tomatoes.
            Only after chopping 2 tbsp cilantro, and if we have all the ingredients, we can then add the chopped cilantro to the bowl.
            Only after START, and if we have all the ingredients, we can then add 1/2 tsp ground black pepper to the bowl.
            We have ground black pepper.
            We have oil.
            Only after scooping the tomatoes from the pan, and if we have all the ingredients, we can then put tomatoes on a serving plate.
            Only after pouring the egg mixture into the pan, and if we have all the ingredients, we can then stir gently so the set egg on the base moves and uncooked egg flows into the space.
            Only after transferring the omelette to the plate and serving with the tomatoes, and if we have all the ingredients, we can then END.
            Only after adding the chopped cilantro to the bowl, cracking one egg into a bowl, and adding 1/2 tsp ground black pepper to the bowl, and if we have all the ingredients, we can then beat the contents of the bowl.
            Only after heating 1 tbsp oil in a non-stick frying pan, and if we have all the ingredients, we can then cook the tomatoes cut-side down until softened and colored.
            Only after START, and if we have all the ingredients, we can then crack one egg into a bowl.
            Only after cooking the tomatoes cut-side down until softened and colored, and if we have all the ingredients, we can then scoop the tomatoes from the pan.
            Only after START, and if we have all the ingredients, we can then take a tomato.
            Only after beating the bowl contents and cutting the tomato into two pieces, and if we have all the ingredients, we can then heat 1 tbsp oil in a non-stick frying pan.
            We have egg.
            Only after START, and if we have all the ingredients, we can then chop 2 tbsp cilantro.
            Only after stirring gently so the set egg moves and uncooked egg flows, and if we have all the ingredients, we can then stop stirring when it’s nearly cooked to let it set into an omelette.
            We have tomato.
            We now START.
          </td>
          <td class="sticky-gt gt"></td>
          <td colspan="8"></td>
        </tr>

        <!-- int1 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 1: We can now <strong>Chop 2 tbsp cilantro</strong>.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.35</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int2 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 2: We can now <strong>Crack one egg</strong> in a bowl.</span></td>
          <td class="sticky-gt gt"><span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>0.85</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
        </tr>

        <!-- int3 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 3: We can now <strong>Take a tomato</strong>.</span></td>
          <td class="sticky-gt gt"><span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>0.98</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
        </tr>

        <!-- int4 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 4: We can now <strong>Add 1/2 tsp ground black pepper</strong> to the bowl.</span></td>
          <td class="sticky-gt gt"><span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>0.80</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
        </tr>

        <!-- int5 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 5: We can now <strong>Add the chopped cilantro</strong> to the bowl.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int6 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 6: We can now <strong>Cut the tomato</strong> into two pieces.</span></td>
          <td class="sticky-gt gt"><span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>0.96</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric">0.00 <span class="chip bad">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok thick">✓</span></td>
        </tr>

        <!-- int7 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 7: We can now <strong>Beat the contents</strong> of the bowl.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.01</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int8 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 8: We can now <strong>Heat 1 tbsp oil</strong> in a non-stick pan.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int9 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 9: We can now <strong>Cook tomatoes</strong> cut-side down until softened and colored.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.01</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int10 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 10: We can now <strong>Scoop the tomatoes</strong> from the pan.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.21</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int11 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 11: We can now <strong>Put tomatoes on a serving plate</strong>.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.18</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int12 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 12: We can now <strong>Pour the egg mixture</strong> into the pan.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.18</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int13 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 13: We can now <strong>Stir gently</strong> so set egg moves and uncooked egg flows.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.19</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int14 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 14: We can now <strong>Stop stirring</strong> to let it set into an omelette.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.19</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int15 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 15: We can now <strong>Transfer the omelette</strong> to the plate and serve with tomatoes.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>

        <!-- int16 -->
        <tr>
          <td class="sticky-claim"><span class="claim-text">Derived Claim 16: We can now <strong>END</strong>.</span></td>
          <td class="sticky-gt gt"><span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>1.00</strong> <span class="chip ok">✓</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric"><strong>0.00</strong> <span class="chip bad thick">✗</span></td>
          <td class="metric">1.00 <span class="chip ok">✓</span></td>
        </tr>
      </tbody>
    </table>
  </div>

  <div class="claims-caption">
    <strong>CaptainCook4D example.</strong> Context concatenates all prerequisite sentences (base claims). Derived Claims 1 - 16 show method scores and decisions (✓/✗), with thick borders marking agreement with ground truth.
  </div>
</div>

</div>
</details>

<!-- We evaluate ARES against various LLM-judge and entailment-based baselines four benchmarks, including our new synthetic dataset, ClaimTrees, which features long chains with controllable propagated errors based on graphs. -->

We can also see that ARES can robustly identify error propagations in long reasoning chains in ClaimTrees up to even chains with 50 steps.

<div id="claimtrees_gpt-4o-mini"></div>

<figcaption>
  <strong>(ClaimTrees) GPT-4o-mini.</strong> ARES can robustly identify error propagations in long reasoning chains, whereas other methods fail.
</figcaption>




<!-- Experiments confirm that ARES excels at identifying these propagated errors. As shown in the above figure, ARES maintains a high Macro-F1 score on chains up to 50 steps, while baseline performance deteriorates sharply. This superior performance, illustrated with a concrete example in the following example, is consistent across all datasets. -->


### ARES detects more errors on diverse benchmarks

We systemmatically compare ARES with all baselines on [PRMBench](https://arxiv.org/abs/2501.03124) and [DeltaBench](https://openstellarteam.github.io/DeltaBench/) in addition to our synthetic datasets ClaimTrees and CaptainCookRecipes.
We report Macro-F1 on error detection by thresholding the soundness scores from each method based on a 5-fold cross validation.
<!-- We also find that ARES performs well on 2 natural and 2 synthetic benchmarks: -->

<div id="benchmarks_gpt-4o-mini"></div>


<figcaption>
  <strong>(Benchmarks) GPT-4o-mini.</strong> ARES detects the most errors on 2 natural (PRMBench, DeltaBench) and 2 synthetic
  (ClaimTrees, CaptainCook) benchmarks. For synthetic sets we construct reasoning chains from ground-truth logic/recipe
  graphs and remove certain rules to induce propagated errors. The error bar is the standard deviation among 5-fold cross validation.
</figcaption>

<!-- We find that ARES detects the most error across all datasets when prompting GPT-4o-mini to be the backbone entailment model.
ARES is especially better than other methods on our synthetic datasets with known propagated errors.
For CaptainCookRecipes, potentially because the recipe graphs has fewer propagated errors comparing to linear chains in ClaimTrees, Entail-Prev is only slightly behind ARES.
Also, as there are many different claims in the premises and more fuzzy natural language cooking reasoning, it is harder for ARES to achieve perfect reasoning.
LLM judge performs on par with ARES on DeltaBench, which contains long reasoning chains generated by thinking models, with ROSCOE-Inter following it.
This could be because for DeltaBench the first error is already reliably labeled, while they do not always consider propagated errors as unsound.
On PRMBench, the reasoning chains are mostly short (around 10 claims) and have fewer errors that need multiple claims as premise, making it also slightly easier for ROSCOE-Inter and LLM judge. -->

ARES detects the most errors across all datasets when using GPT-4o-mini as the entailment model, with especially strong gains on synthetic datasets where propagated errors are known. On CaptainCookRecipes, which contains fewer propagated errors than the linear chains in ClaimTrees, Entail-Prev performs only slightly worse, and the fuzzier cooking logic makes perfect reasoning harder for ARES. On DeltaBench, LLM-Judge matches ARES and ROSCOE-Inter follows, likely because the first error is reliably labeled while propagated errors are not consistently treated as unsound. For PRMBench, the shorter chains (≈10 claims) and fewer multi-premise errors make the task easier, narrowing the gap between methods.

<!-- We attribute this success to ARES being the only method that satisfies all key desiderata for error detection: 
- **_Robust:_** previous errors do not adversely affect the current step.
- **_Causal:_** downstream steps do not affect the current step.
- **_Sufficient:_** all relevant claims are included as premise when assessing. -->

## Conclusion
In this blog post, we showed that ARES offers a novel approach to inductively assess reasoning soundness by probabilistically considering only previous sound claims as premises.
It is sample efficient and provides a more principled and reliable method for detecting errors in reasoning chains.


For more details, see our [paper](https://arxiv.org/abs/2507.12948) and [code](https://github.com/fallcat/ares).


## Citation

```bibtex
@inproceedings{
you2025probabilistic,
title={Probabilistic Soundness Guarantees in {LLM} Reasoning Chains},
author={Weiqiu You and Anton Xue and Shreya Havaldar and Delip Rao and Helen Jin and Chris Callison-Burch and Eric Wong},
booktitle={The 2025 Conference on Empirical Methods in Natural Language Processing},
year={2025},
url={https://arxiv.org/abs/2507.12948}
}
```

<script>
window.addEventListener('DOMContentLoaded', () => {
  fetch("{{ '/assets/images/ares/claimtrees_gpt-4o-mini.json' | relative_url }}")
    .then(r => r.json())
    .then(d => plotMultiSeriesFromData(
      d,
      "claimtrees_gpt-4o-mini",
      "(ClaimTrees) GPT-4o-mini - ARES vs. Baselines",
      { legendCols: 2 }
    ));

  fetch("{{ '/assets/images/ares/benchmarks_gpt-4o-mini.json' | relative_url }}")
    .then(r => r.json())
    .then(d => {
      plotBarGroupsFromData(
        d,
        "benchmarks_gpt-4o-mini",
        { titleSize: 22, axisTitleSize: 16, tickSize: 13, legendFontSize: 13 }
      );
    });
});
</script>
